import argparse
from pathlib import Path
import uuid
import cv2
import numpy as np
from tensorflow import keras

from ocr_app.config import SheetConfig
from ocr_app.labels import DIGIT_LABELS, LABEL_TO_CHAR, LETTER_LABELS, choose_allowed_label
from ocr_app.model import load_labels
from ocr_app.preprocessing import align_image, load_image, preprocess_cell

# ÐžÐ±Ñ€Ð°Ñ‚Ð½Ñ‹Ð¹ Ð¼Ð°Ð¿Ð¿Ð¸Ð½Ð³ Ð´Ð»Ñ ÑƒÐ´Ð¾Ð±ÑÑ‚Ð²Ð° (Ð° -> A_cyr)
CHAR_TO_LABEL_LOWER = {char.lower(): label for label, char in LABEL_TO_CHAR.items() if char}


def group_cells(cells):
    grouped = {}
    for cell in cells:
        grouped.setdefault(cell.label, []).append(cell)
    for label, items in grouped.items():
        grouped[label] = sorted(items, key=lambda item: item.index)
    return grouped


def main() -> None:
    repo_root = Path(__file__).resolve().parents[1]
    parser = argparse.ArgumentParser(description="Interactive trainer for full fields.")
    parser.add_argument("--scans", default=str(repo_root / "scans"))
    parser.add_argument("--config", default=str(repo_root / "sheet_config.json"))
    parser.add_argument("--model-dir", default=str(repo_root / "scripts" / "model"))
    parser.add_argument("--dataset", default=str(repo_root / "dataset_review"))
    # Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÐ¼ Ð´ÐµÑ„Ð¾Ð»Ñ‚Ð½Ñ‹Ð¹ Ð¿Ð°Ð´Ð´Ð¸Ð½Ð³ 15, ÐºÐ°Ðº Ð² align_form
    parser.add_argument("--padding", type=int, default=15, help="Top padding used in alignment")
    args = parser.parse_args()

    config = SheetConfig.load(args.config)
    grouped = group_cells(config.cells)

    # ÐŸÐ¾Ñ€ÑÐ´Ð¾Ðº Ð¿Ð¾Ð»ÐµÐ¹: ÑÐ½Ð°Ñ‡Ð°Ð»Ð° Ð¤Ð˜Ðž, Ð¿Ð¾Ñ‚Ð¾Ð¼ Ð¾ÑÑ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ
    field_order = ["last_name", "first_name", "patronymic", "birth_date", "phone"]

    model_dir = Path(args.model_dir)
    model = keras.models.load_model(model_dir / "ocr_model.keras")
    labels = load_labels(model_dir / "labels.json")
    image_size = np.load(model_dir / "image_size.npy")
    size = (int(image_size[0]), int(image_size[1]))

    dataset_root = Path(args.dataset)
    dataset_root.mkdir(parents=True, exist_ok=True)

    scan_paths = sorted(Path(args.scans).glob("*"))
    if not scan_paths:
        raise SystemExit("No scans found.")

    cv2.namedWindow("Field Preview", cv2.WINDOW_NORMAL)
    cv2.resizeWindow("Field Preview", 800, 200)

    for scan_path in scan_paths:
        print(f"\nðŸ“„ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ñ„Ð°Ð¹Ð»Ð°: {scan_path.name}")
        image = load_image(str(scan_path))

        try:
            # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ñ‚Ñƒ Ð¶Ðµ Ð»Ð¾Ð³Ð¸ÐºÑƒ Ð²Ñ‹Ñ€Ð°Ð²Ð½Ð¸Ð²Ð°Ð½Ð¸Ñ, Ñ‡Ñ‚Ð¾ Ð¸ Ð² ÑÑ‚Ð°Ñ€Ñ‹Ñ… ÑÐºÑ€Ð¸Ð¿Ñ‚Ð°Ñ…
            # Ð’Ð°Ð¶Ð½Ð¾: Ð·Ð´ÐµÑÑŒ Ð¼Ñ‹ ÐÐ• Ð²Ñ‹Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼ padding Ð¸Ð· Ð²Ñ‹ÑÐ¾Ñ‚Ñ‹, ÐµÑÐ»Ð¸ Ð² ÐºÐ¾Ð½Ñ„Ð¸Ð³Ðµ Ð·Ð°Ð¿Ð¸ÑÐ°Ð½Ð° Ð¿Ð¾Ð»Ð½Ð°Ñ Ð²Ñ‹ÑÐ¾Ñ‚Ð°.
            # ÐÐ¾ Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð»Ð¾Ð¼Ð°Ñ‚ÑŒ Ð»Ð¾Ð³Ð¸ÐºÑƒ, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ align_image ÐºÐ°Ðº Ð² Ð³ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ðµ CSV
            target_height = config.image_height - args.padding
            aligned = align_image(
                image,
                output_size=(config.image_width, target_height),
                top_padding=args.padding
            )
        except Exception as e:
            print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð²Ñ‹Ñ€Ð°Ð²Ð½Ð¸Ð²Ð°Ð½Ð¸Ñ {scan_path.name}: {e}")
            continue

        for field_name in field_order:
            if field_name not in grouped:
                continue

            cells = grouped[field_name]
            if not cells:
                continue

            # 1. Ð¡Ð±Ð¾Ñ€ Ð´Ð°Ð½Ð½Ñ‹Ñ…
            crops = []
            crop_images_to_save = []  # Ð¡Ñ‹Ñ€Ñ‹Ðµ ÐºÑ€Ð¾Ð¿Ñ‹ Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ (ÐºÐ°Ðº Ð±Ñ‹Ð»Ð¾ Ñ€Ð°Ð½ÑŒÑˆÐµ)

            # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð³Ñ€Ð°Ð½Ð¸Ñ†Ñ‹ Ð¿Ð¾Ð»Ñ Ð´Ð»Ñ Ð¿Ñ€ÐµÐ²ÑŒÑŽ
            min_x = min(c.x for c in cells)
            min_y = min(c.y for c in cells)
            max_x = max(c.x + c.w for c in cells)
            max_y = max(c.y + c.h for c in cells)

            # Ð”ÐµÐ»Ð°ÐµÐ¼ Ð¿Ñ€ÐµÐ²ÑŒÑŽ Ñ Ð·Ð°Ð¿Ð°ÑÐ¾Ð¼
            margin = 10
            field_preview = aligned[
                            max(0, min_y - margin):min(aligned.shape[0], max_y + margin),
                            max(0, min_x - margin):min(aligned.shape[1], max_x + margin)
                            ]

            for cell in cells:
                # Ð¡Ñ‚Ñ€Ð¾Ð³Ð¾ Ð¿Ð¾ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ð°Ð¼ Ð¸Ð· ÐºÐ¾Ð½Ñ„Ð¸Ð³Ð°, Ð±ÐµÐ· Ð»Ð¸ÑˆÐ½Ð¸Ñ… Ð¿Ð°Ð´Ð´Ð¸Ð½Ð³Ð¾Ð²
                crop = aligned[cell.y: cell.y + cell.h, cell.x: cell.x + cell.w]

                # Ð”Ð»Ñ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ñ - Ð¿Ñ€ÐµÐ¿Ñ€Ð¾Ñ†ÐµÑÑÐ¸Ð½Ð³
                processed = preprocess_cell(crop, size)
                crops.append(processed)

                # Ð”Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ - ÐžÐ Ð˜Ð“Ð˜ÐÐÐ›Ð¬ÐÐ«Ð™ ÐºÑ€Ð¾Ð¿ (Ð½Ð¾ Ð² Ñ‡/Ð±, ÐµÑÐ»Ð¸ Ð½Ð°Ð´Ð¾)
                # Ð•ÑÐ»Ð¸ preprocess_cell Ð´ÐµÐ»Ð°ÐµÑ‚ Ð¸Ð½Ð²ÐµÑ€ÑÐ¸ÑŽ, Ñ‚Ð¾ Ð»ÑƒÑ‡ÑˆÐµ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÑ‚ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚ Ð¿Ñ€ÐµÐ¿Ñ€Ð¾Ñ†ÐµÑÑÐ¸Ð½Ð³Ð°,
                # Ð½Ð¾ Ð²Ñ‹ Ð¿Ñ€Ð¾ÑÐ¸Ð»Ð¸ "ÐºÐ°Ðº Ð±Ñ‹Ð»Ð¾". Ð’ ÑÑ‚Ð°Ñ€Ð¾Ð¹ Ð²ÐµÑ€ÑÐ¸Ð¸ ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐ»ÑÑ crop (Ð²Ð¾Ð·Ð¼Ð¾Ð¶Ð½Ð¾, Ð¿Ñ€Ð¾ÑˆÐµÐ´ÑˆÐ¸Ð¹ threshold).
                # Ð§Ñ‚Ð¾Ð±Ñ‹ Ð½Ðµ Ð±Ñ‹Ð»Ð¾ Ñ€Ð°Ð¼Ð¾Ðº, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ crop ÐºÐ°Ðº ÐµÑÑ‚ÑŒ.
                # ÐÐ¾ ÐµÑÐ»Ð¸ Ð¼Ñ‹ Ñ…Ð¾Ñ‚Ð¸Ð¼, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð² Ð´Ð°Ñ‚Ð°ÑÐµÑ‚Ðµ Ð±Ñ‹Ð»Ð¸ Ð³Ð¾Ñ‚Ð¾Ð²Ñ‹Ðµ Ðº Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸ÑŽ ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÐ¸,
                # Ð»ÑƒÑ‡ÑˆÐµ ÑÐ¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ processed, ÐºÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð² uint8.

                # Ð’ÐÐ Ð˜ÐÐÐ¢ "ÐšÐÐš Ð‘Ð«Ð›Ðž": Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ processed, Ð½Ð¾ Ð±ÐµÐ· Ð°Ð³Ñ€ÐµÑÑÐ¸Ð²Ð½Ð¾Ð¹ Ð¾Ñ‡Ð¸ÑÑ‚ÐºÐ¸ Ð³Ñ€Ð°Ð½Ð¸Ñ†,
                # Ð¿Ð¾Ð»Ð°Ð³Ð°ÑÑÑŒ Ð½Ð° Ñ‚Ð¾, Ñ‡Ñ‚Ð¾ ÐºÐ¾Ð¾Ñ€Ð´Ð¸Ð½Ð°Ñ‚Ñ‹ Ð² ÐºÐ¾Ð½Ñ„Ð¸Ð³Ðµ Ñ‚Ð¾Ñ‡Ð½Ñ‹Ðµ.
                to_save = (processed * 255).astype(np.uint8)
                crop_images_to_save.append(to_save)

            if not crops:
                continue

            # 2. Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ
            batch = np.expand_dims(np.array(crops), axis=-1)
            probabilities = model.predict(batch, verbose=0)

            if field_name in {"last_name", "first_name", "patronymic"}:
                allowed = LETTER_LABELS
            else:
                allowed = DIGIT_LABELS

            predicted_chars = []

            for idx in range(len(crops)):
                pred_label = choose_allowed_label(probabilities[idx], labels, allowed)
                char = LABEL_TO_CHAR.get(pred_label, "")
                if pred_label == "Empty":
                    char = "_"
                predicted_chars.append(char)

            predicted_text = "".join(predicted_chars).replace("_", "")

            # 3. Ð’Ð²Ð¾Ð´ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ
            cv2.imshow("Field Preview", field_preview)
            cv2.waitKey(100)

            print(f"ÐŸÐ¾Ð»Ðµ [{field_name}]. Ð Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð½Ð¾: {predicted_text}")
            user_input = input(f"Ð’ÐµÑ€Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚ (Enter='{predicted_text}', 'skip'=Ð´Ð°Ð»ÑŒÑˆÐµ): ").strip()

            if user_input.lower() == 'skip':
                continue

            final_text = predicted_text if user_input == "" else user_input.upper().replace(" ", "")

            # 4. Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ðµ Ð¾ÑˆÐ¸Ð±Ð¾Ðº
            # Ð¡Ð¾Ð¿Ð¾ÑÑ‚Ð°Ð²Ð»ÑÐµÐ¼ Ð±ÑƒÐºÐ²Ñ‹ ÑÐ»ÐµÐ²Ð° Ð½Ð°Ð¿Ñ€Ð°Ð²Ð¾.
            # Ð•ÑÐ»Ð¸ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð²Ð²ÐµÐ» "Ð˜Ð’ÐÐÐžÐ’", Ð±ÐµÑ€ÐµÐ¼ 1-ÑŽ ÑÑ‡ÐµÐ¹ÐºÑƒ -> Ð˜, 2-ÑŽ -> Ð’...

            count_saved = 0
            for i, correct_char in enumerate(final_text):
                if i >= len(crop_images_to_save):
                    break  # Ð¯Ñ‡ÐµÐµÐº Ð¼ÐµÐ½ÑŒÑˆÐµ, Ñ‡ÐµÐ¼ Ð±ÑƒÐºÐ²

                char_lower = correct_char.lower()

                # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð¿Ð°Ð¿ÐºÑƒ Ð½Ð°Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ñ
                if char_lower in CHAR_TO_LABEL_LOWER:
                    label_dir_name = CHAR_TO_LABEL_LOWER[char_lower]
                elif char_lower.isdigit():
                    label_dir_name = char_lower
                else:
                    print(f"âš ï¸ ÐŸÑ€Ð¾Ð¿ÑƒÑÐº ÑÐ¸Ð¼Ð²Ð¾Ð»Ð°: {correct_char}")
                    continue

                # Ð‘ÐµÑ€ÐµÐ¼ ÐºÐ°Ñ€Ñ‚Ð¸Ð½ÐºÑƒ i-Ð¹ ÑÑ‡ÐµÐ¹ÐºÐ¸
                img_to_save = crop_images_to_save[i]

                # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼
                target_dir = dataset_root / label_dir_name
                target_dir.mkdir(exist_ok=True)

                fname = f"{scan_path.stem}_{field_name}_{i}_{uuid.uuid4().hex[:6]}.jpg"

                # imencode Ð´Ð»Ñ ÐºÐ¸Ñ€Ð¸Ð»Ð»Ð¸Ñ†Ñ‹
                is_success, buf = cv2.imencode(".jpg", img_to_save)
                if is_success:
                    buf.tofile(str(target_dir / fname))
                    count_saved += 1

            if count_saved > 0:
                print(f"âœ… Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¾ {count_saved} Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ð¾Ð²")

    cv2.destroyAllWindows()
    print("Ð“Ð¾Ñ‚Ð¾Ð²Ð¾.")


if __name__ == "__main__":
    main()
