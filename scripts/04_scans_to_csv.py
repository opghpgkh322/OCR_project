import argparse
import csv
import json
import difflib
from pathlib import Path
import cv2
import numpy as np
from tensorflow import keras

from ocr_app.config import SheetConfig
from ocr_app.labels import DIGIT_LABELS, LABEL_TO_CHAR, LETTER_LABELS, choose_allowed_label
from ocr_app.model import load_labels
from ocr_app.preprocessing import align_image, load_image, preprocess_cell

# --- –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø ---
CORRECTION_THRESHOLD = 0.75  # –ß—É—Ç—å —Å–Ω–∏–∑–∏–º –ø–æ—Ä–æ–≥, —Ç–∞–∫ –∫–∞–∫ —Ñ–∏–ª—å—Ç—Ä –ø–æ –ø–æ–ª—É —É–±–∏—Ä–∞–µ—Ç –º–Ω–æ–≥–æ –ª–æ–∂–Ω—ã—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤


class GenderedDict:
    """–•—Ä–∞–Ω–∏—Ç —Å–ª–æ–≤–∞—Ä–∏, —Ä–∞–∑–¥–µ–ª–µ–Ω–Ω—ã–µ –ø–æ –ø–æ–ª—É."""

    def __init__(self):
        self.all = set()  # –í—Å–µ —Å–ª–æ–≤–∞ (–¥–ª—è –ø–µ—Ä–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞)
        self.male = set()  # –¢–æ–ª—å–∫–æ –º—É–∂—Å–∫–∏–µ
        self.female = set()  # –¢–æ–ª—å–∫–æ –∂–µ–Ω—Å–∫–∏–µ
        self.map = {}  # –°–ª–æ–≤–æ -> –ü–æ–ª ('m', 'f', –∏–ª–∏ None)

    def add(self, word: str, gender: str = None):
        if not word: return
        w = word.strip().upper()
        self.all.add(w)

        # –ó–∞–ø–æ–º–∏–Ω–∞–µ–º –ø–æ–ª. –ï—Å–ª–∏ —Å–ª–æ–≤–æ —É–∂–µ –µ—Å—Ç—å, –Ω–æ —Å –¥—Ä—É–≥–∏–º –ø–æ–ª–æ–º -> —Å—Ç–∞–≤–∏–º None (—É–Ω–∏—Å–µ–∫—Å)
        if w not in self.map:
            self.map[w] = gender
        elif self.map[w] != gender:
            self.map[w] = None  # –ö–æ–Ω—Ñ–ª–∏–∫—Ç –ø–æ–ª–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –°–ê–®–ê –º/–∂)

        if gender == 'm':
            self.male.add(w)
        elif gender == 'f':
            self.female.add(w)


def load_jsonl_dataset(path: Path) -> GenderedDict:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç JSONL –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å —É—á–µ—Ç–æ–º –ø–æ–ª–∞."""
    db = GenderedDict()
    if not path.exists():
        print(f"‚ö†Ô∏è –ë–∞–∑–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {path}")
        return db

    print(f"‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤–∞—Ä—è: {path.name}...")
    try:
        with open(path, "r", encoding="utf-8") as f:
            for line in f:
                try:
                    data = json.loads(line)
                    word = data.get("text") or data.get("name") or data.get("surname") or data.get("midname")
                    gender = data.get("gender")  # –û–∂–∏–¥–∞–µ–º 'm' –∏–ª–∏ 'f'

                    if word:
                        db.add(word, gender)
                except json.JSONDecodeError:
                    continue
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è {path.name}: {e}")

    print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(db.all)} —Å–ª–æ–≤")
    return db


def correct_text(text: str, db: GenderedDict, target_gender: str = None) -> str:
    """
    –ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç —Ç–µ–∫—Å—Ç.
    –ï—Å–ª–∏ target_gender –∑–∞–¥–∞–Ω ('m' –∏–ª–∏ 'f'), –∏—â–µ—Ç —Ç–æ–ª—å–∫–æ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–º –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–µ.
    """
    if not text:
        return text

    # 1. –í—ã–±–∏—Ä–∞–µ–º –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –ø–æ–∏—Å–∫–∞
    if target_gender == 'm':
        search_space = list(db.male)  # difflib —Ç—Ä–µ–±—É–µ—Ç list
    elif target_gender == 'f':
        search_space = list(db.female)
    else:
        search_space = list(db.all)

    # –ï—Å–ª–∏ —Å–ª–æ–≤–∞—Ä—å –ø—É—Å—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω–µ—Ç —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö), –∏—â–µ–º –≤–µ–∑–¥–µ
    if not search_space:
        search_space = list(db.all)

    # 2. –ï—Å–ª–∏ —Å–ª–æ–≤–æ —É–∂–µ –µ—Å—Ç—å –≤ (–ø—Ä–∞–≤–∏–ª—å–Ω–æ–º) —Å–ª–æ–≤–∞—Ä–µ ‚Äî –Ω–µ —Ç—Ä–æ–≥–∞–µ–º
    if text in search_space:
        return text  # –ò–¥–µ–∞–ª—å–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ

    # 3. –ò—â–µ–º –ø–æ—Ö–æ–∂–∏–µ
    matches = difflib.get_close_matches(text, search_space, n=1, cutoff=CORRECTION_THRESHOLD)
    if matches:
        suggestion = matches[0]
        print(
            f"üîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ ({'–ú' if target_gender == 'm' else '–ñ' if target_gender == 'f' else '?'}) : {text} -> {suggestion}")
        return suggestion

    return text


def group_cells(cells):
    grouped = {}
    for cell in cells:
        grouped.setdefault(cell.label, []).append(cell)
    for label, items in grouped.items():
        grouped[label] = sorted(items, key=lambda item: item.index)
    return grouped


def is_empty_crop(image: np.ndarray, threshold: float = 0.015) -> bool:
    return np.mean(image) < threshold


def main() -> None:
    repo_root = Path(__file__).resolve().parents[1]
    dict_dir = repo_root / "dictionaries"

    parser = argparse.ArgumentParser(description="Run OCR on scans and export CSV.")
    parser.add_argument("--scans", default=str(repo_root / "scans"))
    parser.add_argument("--config", default=str(repo_root / "sheet_config.json"))
    parser.add_argument("--model-dir", default=str(repo_root / "scripts" / "model"))
    parser.add_argument("--output", default=str(repo_root / "output.csv"))
    parser.add_argument("--padding", type=int, default=15)
    parser.add_argument("--no-correct", action="store_true")
    args = parser.parse_args()

    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ —É–º–Ω—ã—Ö —Å–ª–æ–≤–∞—Ä–µ–π
    surnames_db = GenderedDict()
    names_db = GenderedDict()
    midnames_db = GenderedDict()

    if not args.no_correct:
        print("--- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–ª–æ–≤–∞—Ä–µ–π ---")
        surnames_db = load_jsonl_dataset(dict_dir / "surnames_table.jsonl")
        names_db = load_jsonl_dataset(dict_dir / "names_table.jsonl")
        midnames_db = load_jsonl_dataset(dict_dir / "midnames_table.jsonl")
        print("------------------------------")

    config = SheetConfig.load(args.config)
    grouped = group_cells(config.cells)

    # –ú–æ–¥–µ–ª—å
    model_dir = Path(args.model_dir)
    model = keras.models.load_model(model_dir / "ocr_model.keras")
    labels = load_labels(model_dir / "labels.json")
    image_size = np.load(model_dir / "image_size.npy")
    size = (int(image_size[0]), int(image_size[1]))

    scan_paths = sorted(Path(args.scans).glob("*"))
    if not scan_paths:
        raise SystemExit("No scans found.")

    with open(args.output, "w", newline="", encoding="utf-8") as handle:
        writer = csv.DictWriter(
            handle,
            fieldnames=["filename", "last_name", "first_name", "patronymic", "birth_date", "phone"],
        )
        writer.writeheader()

        for scan_path in scan_paths:
            print(f"Processing {scan_path.name}...")
            image = load_image(str(scan_path))

            try:
                target_height = config.image_height - args.padding
                aligned = align_image(
                    image,
                    output_size=(config.image_width, target_height),
                    top_padding=args.padding
                )
            except Exception as e:
                print(f"Skipping {scan_path.name}: alignment failed ({e})")
                continue

            # –°–Ω–∞—á–∞–ª–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–µ–º –í–°–Å –≤ —Å—ã—Ä–æ–º –≤–∏–¥–µ
            raw_data = {
                "filename": scan_path.name,
                "last_name": "", "first_name": "", "patronymic": "",
                "birth_date": "", "phone": "",
            }

            for label_name, cells in grouped.items():
                crops = []
                crop_padding = 2

                for cell in cells:
                    y1 = max(0, cell.y - crop_padding)
                    y2 = min(aligned.shape[0], cell.y + cell.h + crop_padding)
                    x1 = max(0, cell.x - crop_padding)
                    x2 = min(aligned.shape[1], cell.x + cell.w + crop_padding)

                    crop = aligned[y1:y2, x1:x2]
                    processed = preprocess_cell(crop, size)

                    if is_empty_crop(processed, threshold=0.015):
                        continue
                    crops.append(processed)

                if not crops:
                    continue

                batch = np.expand_dims(np.array(crops), axis=-1)
                probabilities = model.predict(batch, verbose=0)

                if label_name in {"last_name", "first_name", "patronymic"}:
                    allowed = LETTER_LABELS
                elif label_name in {"birth_date", "phone"}:
                    allowed = DIGIT_LABELS
                else:
                    allowed = set(labels)

                predictions = []
                for idx in range(len(crops)):
                    pred_label = choose_allowed_label(probabilities[idx], labels, allowed)
                    if pred_label == "Empty": continue
                    char = LABEL_TO_CHAR.get(pred_label, "")
                    predictions.append(char)

                raw_data[label_name] = "".join(predictions)

            # --- –ò–ù–¢–ï–õ–õ–ï–ö–¢–£–ê–õ–¨–ù–ê–Ø –ö–û–†–†–ï–ö–¶–ò–Ø ---
            final_row = raw_data.copy()

            if not args.no_correct:
                detected_gender = None

                # 1. –°–Ω–∞—á–∞–ª–∞ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º –ò–ú–Ø (—Å–∞–º—ã–π –Ω–∞–¥–µ–∂–Ω—ã–π –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø–æ–ª–∞)
                raw_name = raw_data["first_name"]
                if raw_name:
                    # –ò—â–µ–º –±–µ–∑ —Ñ–∏–ª—å—Ç—Ä–∞ –ø–æ–ª–∞ —Å–Ω–∞—á–∞–ª–∞
                    corrected_name = correct_text(raw_name, names_db)
                    final_row["first_name"] = corrected_name

                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ–ª –ø–æ –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ú–£ –∏–º–µ–Ω–∏
                    detected_gender = names_db.map.get(corrected_name)
                    if detected_gender:
                        print(f"   –ü–æ–ª –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –ø–æ –∏–º–µ–Ω–∏ ({corrected_name}): {detected_gender}")
                    else:
                        print(f"   –ü–æ–ª –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω (–∏–º—è {corrected_name} –Ω–µ—Ç –≤ –±–∞–∑–µ –∏–ª–∏ —É–Ω–∏—Å–µ–∫—Å)")

                # 2. –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –§–∞–º–∏–ª–∏—é (—Å —É—á–µ—Ç–æ–º –ø–æ–ª–∞)
                if raw_data["last_name"]:
                    final_row["last_name"] = correct_text(
                        raw_data["last_name"],
                        surnames_db,
                        target_gender=detected_gender
                    )

                # 3. –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –û—Ç—á–µ—Å—Ç–≤–æ (—Å —É—á–µ—Ç–æ–º –ø–æ–ª–∞)
                if raw_data["patronymic"]:
                    final_row["patronymic"] = correct_text(
                        raw_data["patronymic"],
                        midnames_db,
                        target_gender=detected_gender
                    )

            writer.writerow(final_row)

    print(f"Saved CSV to {args.output}")


if __name__ == "__main__":
    main()
